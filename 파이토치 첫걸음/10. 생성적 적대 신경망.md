# 생성적 적대 신경망 (GAN)
<br>

## 생성적 적대적 신경망  (Generative Adversarial Network)
<br>

* 생성적 적대 신경망 : 2014년에 처음 소개된 학습 방식
* 이름에서 알 수 있듯 생성 모델과 구분 모델로 나뉨
* 생성 모델은 데이터를 생성해내는 모델
* 구분 모델은 생성된 데이터와 원래 이미지를 구분하는 모델

<img src ="https://t1.daumcdn.net/cfile/tistory/9933034C5B30A59B04" width="800" height = "350">

* 생성자(Generator) : 어떠한 입력 z를 받아 가짜 데이터 생성
* 구분자(Discriminator) : 실제 데이터와 가짜 데이터를 받아 어떤 것이 실제 데이터인지 구분
* 입력으로 들어오는 z는 생성하는 데이터에 따라 다르지만 일반적인 벡터의 형태여도 가능
* 구분자에는 실제 데이터의 경우 1, 가짜 데이터의 경우 0의 라벨이 주로 들어감
* 생성자는 생성한 가짜 데이터가 1에 가깝도록 학습하고 구분자는 가짜 데이터를 0에 가깝도록 분류하는 것이 학습의 목표가 됨
* GAN의 목적 함수

![수식](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cunderset%7BG%7D%7Bmin%7D%5Cunderset%7BD%7D%7Bmax%7D%20%5C%2C%20V%28D%2CG%29%3D%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20P_%7Bdata%7D%28x%29%7D%5B%5Clog%20D%28x%29%5D%20&plus;%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20P_z%28z%29%7D%5B%5Clog%20%281-D%28G%28Z%29%29%5D)

* 위 수식을 G, D에 대해서 분리할 수 있음
* D에 대해서 분리

![수식](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cunderset%7BD%7D%7Bmax%7D%20%5C%2C%20V%28D%2CG%29%3D%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20P_%7Bdata%7D%28x%29%7D%5B%5Clog%20D%28x%29%5D%20&plus;%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20P_z%28z%29%7D%5B%5Clog%20%281-D%28G%28Z%29%29%5D)

* D (구분자) 입장에서 위 수식을 최대화 : 각 항의 기댓값(로그 부분)이 최대가 되어야함
	* D(x) 는 1, D(G(z))는 0이 되어야 함 (실제는 1, 가짜는 0)
	<br>

* G에 대해서 분리

![수식](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cunderset%7BG%7D%7Bmin%7D%20%5C%2C%20V%28D%2CG%29%20%3D%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20P_%7Bdata%7D%28x%29%7D%5B%5Clog%20D%28x%29%5D&plus;%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20P_z%28z%29%7D%5B%5Clog%20%281-D%28G%28z%29%29%5D)

* G의 입장에서는 수식의 뒷 부분에 관여 가능 (이 부분이 최소화)
	* 이 값을 최소화하려면 1-D(G(z)) 가 0이 되어야 함 (D(G(z)) 가 1이어야 함)
	* 결국 구분자에 의해 걸러지는 가짜를 최대한 작게 만들어야 함
	<br>

## 모델 구현 및 학습
<br>

* GAN에 필요한 목적 함수를 구현하기 위해서는 간단한 트릭이 필요
* 구분자의 목적 함수를 손실 함수의 형태로 변형

![수식](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cunderset%7BD%7D%7Bmin%7D%20%5C%2C%20V%28D%2CG%29%20%3D%20-%20%5Cmathbb%7BE%7D_%7Bx%20%5Csim%20p_%7Bdata%7D%28x%29%7D%5B%5Clog%20D%28x%29%5D)

* 앞에 마이너스를 붙여 손실 함수 형태로 만들면 교차 엔트로피 수식과 같아짐
* 생성자의 경우도 아래와 같이 목적 함수를 바꾸면 학습에 유리

![수식](https://latex.codecogs.com/gif.latex?%5Cinline%20%5Cunderset%7BG%7D%7Bmax%7D%20%5C%2C%20V%28D%2CG%29%20%3D%20%5Cmathbb%7BE%7D_%7Bz%20%5Csim%20p_%7Bz%7D%28z%29%7D%5B%5Clog%20D%28G%28z%29%29%5D)

* 여기에 마이너스를 붙이면 교차 엔트로피 수식과 같아짐

* MNIST 데이터를 생성하고 구분하는 간단한 GAN

#### model.py

```python
import torch
import torch.nn as nn
from collections import OrderedDict

class Generator(nn.Module):
    
    def __init__(self, z_size, middle_size, batch_size):
        super(Generator, self).__init__()
        self.batch_size = batch_size
        self.layer1 = nn.Sequential(
            OrderedDict([
                ('fc1', nn.Linear(z_size, middle_size)),
                ('bn1', nn.BatchNorm1d(middle_size)),
                ('act1', nn.ReLU())
                ]))
        
        self.layer2 = nn.Sequential(
            OrderedDict([
                ('fc2',nn.Linear(middle_size, 784)),
                ('bn2', nn.BatchNorm2d(784)),
                ('tanh', nn.Tanh())
                ]))
        
    def forward(self, z):
        out = self.layer1(z)
        out = self.layer2(out)
        out = out.view(self.batch_size, 1, 28, 28)
        return out
    
class Discriminator(nn.Module):
    
    def __init__(self, middle_size, batch_size):
        super(Discriminator, self).__init__()
        self.batch_size = batch_size
        self.layer1 = nn.Sequential(
            OrderedDict([
                ('fc1', nn.Linear(784, middle_size)),
                ('bn1', nn.BatchNorm1d(middle_size)),
                ('act1', nn.LeakyReLU())
                ]))
        self.layer2 = nn.Sequential(
            OrderedDict([
                ('fc2', nn.Linear(middle_size, 1)),
                ('bn2', nn.BatchNorm1d(1)),
                ('act2', nn.Sigmoid())
                ]))
    
    def forward(self, x):
        out = x.view(self.batch_size, -1)
        out = self.layer1(out)
        out = self.layer2(out)
        return out
```

* Orderdict을 통해 각 레이어마다 이름 부여
	* self.name = nn.Sequential() 이런 식으로 하면 sequential 내 전체가 name으로 묶이긴 함 

#### main.py

```python
generator = Generator(z_size, middle_size, batch_size)
discriminator = Discriminator(middle_size, batch_size)

generator = nn.DataParallel(Generator(), device_ids = [0,1,2,3,4,5,6,7])
discriminator = nn.DataParallel(Discriminator(), device_ids = [0,1,2,3,4,5,6,7])

criterion = nn.MSELoss()
gen_optim = torch.optim.Adam(generator.parameters(), lr = lr, betas = (0.5, 0.999))
dis_optim = torch.optim.Adam(discriminator.parameters(), lr = lr, betas=(0.5,0.999))

ones_label = torch.ones(batch_size, 1)
zeros_label = torch.zeros(batch_size, 1)

for i in range(epochs):
    for _, (image, label) in enumerate(trian_loader):
        
        # 구분자 학습
        dis_optim.zero_grad()
        z = nn.init.normal_(torch.Tensor(batch_size, z_size), mean=0, std = 0.1)
        gen_fake = generator(z)
        dis_fake = discriminator(gen_fake)
        
        dis_real = discriminator(image)
        dis_loss = torch.sum(criterion(dis_fake, zeros_label))
        + torch.sum(criterion(dis_real, ones_label))
        dis_loss.backward(retain_graph = True)
        dis_optim.step()
        
        # 생성자 학습
        gen_optim.zero_grad()
        
        z = nn.init.normal_(torch.Tensor(batch_size, z_size), mean=0, std = 0.1)
        gen_fake = generator(z)
        dis_fake = discriminator(gen_fake)
        
        gen_loss = torch.sum(criterion(dis_fake, ones_label))
        gen_loss.backward()
        gen_optim.step()
```

* z를 정규분포를 통해 생성
* 이를 생성자, 구분자에 나누어 학습
* Linear가 아닌 Conv 레이어를 사용하고 모델의 깊이를 깊게 하면 더 좋은 성능이 나옴
<br>

## 유명한 모델들과 원리
<br>

#### DCGAN (Deep Convolutional GAN)
* 모델 구조

<img src="https://mblogthumb-phinf.pstatic.net/MjAxOTA5MDVfMjQ2/MDAxNTY3Njc3NjMwMTk1.LPzZsZ9wnhnkVXEo9QZYuDHE36Zg_8NqPjg-ga2wsQkg.YGs3MiFHX7rZjsDAs2uVugDKS9p1BbdkKxHql5DzXGgg.PNG.intelliz/dcgan.png?type=w800" width = "800" height="300">

* GAN은 일반적인 지도학습에 비해 학습이 어려움
* 해당 논문에서는 GAN의 학습 성능을 높일 수 있는 방법을 제시 
	* 풀링 연산을 합성곱 연산으로 대체, 생성자 네트워크는 전치 합성곱 연산 사용
	* 생성자와 구분자에 배치 정규화를 사용
	* 완전 연결 네트워크를 사용하지 않음
	* 생성자 네트워크에는 마지막에 사용되는 하이퍼볼릭 탄젠트 함수 외에는 모든 활성화 함수에 렐루를 사용
	* 구분자 네트워크의 모든 활성화 함수로는 리키 렐루 사용
* z로 길이 100짜리 벡터를 사용했는데 다른 값들은 고정하고 하나의 값만 연속적으로 바꾸면서 실험 진행 *(잠재 공간 보간 Latent space interpolation)*
	* 이를 통해 네트워크가 데이터를 외운 것이 아니라 어떤 특성을 학습했다는 점을 알 수 있음
	* z의 특성 중에 어떤 요소가 어떤 특징을 만들어 내는지를 확인할 수 있음
	<br>

#### SRGAN (Super-Resolution GAN)
* 슈퍼 레졸루션 : 저화질의 이미지를 받아서 고화질로 변환하는 작업
* 저화질에서 고화질로의 변환은 경우의 수가 매우 많음
  * 세부적인 형태에 대한 정보가 사라진 상태이므로 세부적인 형태에 대한 다양한 경우의 수 존재
  * 일반적인 평균제곱오차로 모델을 학습하면 다양한 경우에 대해 가장 손실을 적게 만드는 평균적인 고화질 영상을 생성
  * 이렇게 하면 어딘가 흐릿한 영상이 생기기 마련
* GAN은 실제와 비슷한 영상을 만들어 구분자를 속여야 하므로 여러가지 고화질 영상 중에서도 특정한 경우를 생성함 
  * 이를 **(모드 붕괴 mode collapse)** 라고 함 (생성자가 구분자를 속일 수 있는 특정 데이터만 만들어내는 현상)
  * 보통 특정 데이터만 만들어 내는 GAN의 특성은 단점으로 작용하기도 하지만 이 작업의 경우 장점으로 작용
* 또 다른 GAN의 특성으로 *진동(Oslillation)* 이 있음
  * 생성된 결과가 계속 변하는 특성
  * 학습이 이루어지는 동안 가능한 다양한 경우를 왔다갔다 하면서 생성하는 현상
  * 조건부 GAN처럼 추가적인 조건을 부여하면 완화되기도 함
  <br>

#### 텍스트 이미지 합성
* 텍스트를 받아서 이미지를 생성하는 것
* 모델 구조

<img src="https://camo.githubusercontent.com/33bfe0eb57e1729e6f83d2d83fe5453d4bbf3af18c08dceb203c0a97adf2cdae/687474703a2f2f692e696d6775722e636f6d2f644e6c32486b5a2e6a7067" width="900" height="300">

* 특정 문장을 벡터화하고 이를 랜덤 노이즈와 함께 생성자에 전달
* 구분자에 생성된 이미지를 넣을 때 벡터화했던 문장을 조건으로 전달
* 이렇게 하면 특정 문장을 조건으로 이미지를 생성하고 같은 문장을 조건으로 생성된 이미지인지 아닌지를 구분하는 조건부 GAN 모델이 만들어지게 됨
<br>

#### Pix2Pix
* 조건을 주고 데이터를 생성하는 모델 (이미지를 조건으로 줌)
* 모델 구조

<img src="https://blog.kakaocdn.net/dn/dG3yWO/btq5i2yK9KW/BE1961uawwcYpfzCA9vzu1/img.png" width="750" height="250">

* x라는 조건 이미지를 주고 G(x)를 생성
* 구분자는 x와 G(x)가 진짜 쌍인지를 구분
* 다양한 영역에 활용이 가능한 방식
<br>

#### CycleGAN과 DiscoGAN
* Pix2Pix 방식은 x와 G(x)의 실제 쌍 데이터가 필요하다는 단점이 존재
* 이를 극복한 모델이 CycleGAN (Cycle-consistent adversarial network)
* DiscoGAN과 CycleGAN은 유사한 구조를 가지고 있음
* 모델 구조 (DiscoGAN)

<img src="https://raw.githubusercontent.com/carpedm20/DiscoGAN-pytorch/master/assets/model.png" width="700" height="600">

* 금발에서 흑발로 바꾸고 싶다면 금발 데이터와 흑발 데이터를 여러 장 모음
	* 이 때, 머리색 외에 다른 조건은 최대한 일정하게 유지
	* 다른 조건을 일정하게 유지하는 것이 학습의 성능에 영향을 미침
* 학습 시 크게 두 가지 변환이 학습됨
	* 금발에서 흑발로의 변환 (도메인 A에서 도메인 B로)
	* 흑발에서 금발로의 변환 (도메인 B에서 도메인 A로)
* 각 도메인에서 변환된 생성 이미지들은 구분자에 들어가 생성된 이미지인지를 구분받게 됨
* 이 때 *복원 손실 함수* 를 통해 A에서 B로 변환된 이미지를 다시 A로 복원했을 때 차이를 손실 함수로 정의하고 이를 최소화하도록 학습
	* 이를 통해 원본 이미지의 형태를 유지하면서 B도메인의 특성만 변환하게 됨