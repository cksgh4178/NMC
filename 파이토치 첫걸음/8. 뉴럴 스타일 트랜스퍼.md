# 뉴럴 스타일 트랜스퍼
<br>

## 전이 학습
<br>

* 특정 조건에서 얻어진 어떤 지식을 다른 상황에 맞게 *전이* 해서 활용하는 학습 방법
* 전이 학습의 장점
	* 데이터 부족을 해결할 수 있음
	* 학습에 걸리는 시간이 줄어듬
	* 시뮬레이션에서 학습된 모델을 현실에 적용할 수 있게 해줌

<img src="https://miro.medium.com/max/1000/1*mA1sUreCxnl-65ljlaXEcA.jpeg" width ="800" height = "350">

* 미리 학습된 네트워크에서 완전 연결층만 제외한 부분을 활용
	* 특성 추출기(feature extractor) 이라고도 함
* 새로운 완전 연결층을 결합한 후 특성 추출기는 고정시켜놓고 완전 연결층만 새로 학습
* 예제 코드

```python
import torchvision.models as models
resnet = models.resnet50(pretrained = True)
```

* 이미 학습된 (pretrained true) 모델 가져오기 (특성 추출기로 사용)

```python
for name, module in resnet.named_children():
	print(name)
```

* 파이토치의 module 에는 기본적으로 named_module이라는 함수 내장
	* self.conv = nn.Sequential(...) 이런 식으로 작성하면 conv가 하나의 child가 됨
	* 여기서 완전 연결 부분 (fc)만 새로 작성

```python
import torch
import torch.nn as nn

class Resnet(nn.Module):
    
    def __init__(self, batch_size, extractor, num_categories):
        super(Resnet, self).__init__()
        self.batch_size = batch_size
        self.extractor = nn.Sequentail(*list(extractor.children())[0:-1])
        self.fc_layer = nn.Sequential(
            nn.Linear(2048, 500),
            nn.BatchNorm1d(500),
            nn.ReLU(),
            nn.Linear(500, num_categories),
            nn.ReLU()
            )
    
    def forward(self, x):
        out = self.extractor(x)
        out = out.view(self.batch_size, -1)
        out = self.fc_layer(out)
        return out
```

* named_children 대신 children()을 쓰면 모듈들만 불러옴
* \*list 는 list의 내용물만 전달 (unpacking 과정)
* 이 때 extractor의 파라미터는 학습 과정에서 업데이트되면 안되므로 이를 명시해주는 코드 작성

```python
for params in model.extractor.parameters():
	params.require_grad = False

for params in model.fc_layer.parameters():
	params.require_grad = True
```

## 스타일 트랜스퍼
<br>

* 스타일 : 다른 필터 응답들 간의 연관성 (필터 활성도의 그람 행렬)
* 컨텐츠 : 스타일과 대비되는 형태로 *컨텐츠 표현 (content representation)* 이란 더 높은 레이어 내의 특성 응답
* 스타일 트랜스퍼의 구조

<img src="https://media.vlpt.us/images/goe87088/post/1789ccb3-8855-46bd-a971-725d32c3939b/image.png" width="800" height="500">

* 총 손실은 컨텐츠 손실과 스타일 손실에 각각의 가중치를 곱한 값
* 컨텐츠 손실은 4번째 레이어에서만 발생하지만 스타일 손실은 모든 층에서 발생
	* 모델의 위치에 따라 수용 영역이 달라지기 때문에 스타일 손실이 모두 다름
* 스타일 손실에 대한 가중치가 커질수록 원래 그림의 형태가 사라짐
* 컨텐츠 손실을 계산한 위치가 입력 이미지에 가까울수록(더 낮은 레이어에서 계산) 원본 이미지의 위치 정보가 잘 유지
* 최적화 알고리즘은 2차 미분값을 활용하는 L-BFGS 사용
	* 2차 미분 최적화 방법인 뉴턴 메소드(Newton's method)를 근사한 방법 (BFGS)
	* 이를 m개의 1차 미분값만을 사용한 방법이 L-BFGS
	* 1차 미분, 2차 미분을 활용한 방법은 학습 방법론 자체에 대한 논문들이 많이 다루고 있음